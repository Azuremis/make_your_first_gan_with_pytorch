{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist_classifier",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMj9cdb3XwFdqmhd8Xn3I5/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Azuremis/make_your_first_gan_with_pytorch/blob/master/mnist_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGSRn5JSYD-O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b371b502-28bf-42d9-b0a9-b0ca2d231c70"
      },
      "source": [
        "# mount drive to read data files\n",
        "from google.colab import drive\n",
        "drive.mount(\"./mount\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at ./mount; to attempt to forcibly remount, call drive.mount(\"./mount\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzvAdCz3Aj_a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import libraries\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "import pandas \n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54b3P2HkfCc3",
        "colab_type": "text"
      },
      "source": [
        "MNIST dataset class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naTCCxn2MPGM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MnistDataset(Dataset):\n",
        "  \n",
        "  def __init__(self, csv_file):\n",
        "    self.data_df = pandas.read_csv(csv_file, header=None)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data_df)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    # mage target (label)\n",
        "    label = self.data_df.iloc[index, 0]\n",
        "    target = torch.zeros((10))  # create target tensor \n",
        "    target[label] = 1.0  # using one hot encoding\n",
        "\n",
        "    # image data (normalise from 0-255 to 0-1)\n",
        "    image_values = torch.FloatTensor(self.data_df.iloc[index, 1:].values) / 255.0\n",
        "\n",
        "    # return label, image data and target tensor\n",
        "    return label, image_values, target\n",
        "\n",
        "  def plot_image(self, index):\n",
        "    # visualise image from pixels\n",
        "    img_arr = self.data_df.iloc[index, 1:].values.reshape(28, 28) \n",
        "    plt.title(\"Label: \" + str(self.data_df.iloc[index, 0]))\n",
        "    plt.imshow(img_arr, interpolation='none', cmap=\"Blues\")\n",
        "    plt.show()\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgGCoq0fcTga",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist_dataset = MnistDataset('mount/My Drive/Colab Notebooks/make_your_first_gan_with_pytorch/mnist_data/mnist_train.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41eKndnvdMFE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "4cb0aac4-93d1-4160-eb57-9f8fc81c6eb0"
      },
      "source": [
        "mnist_dataset.plot_image(9)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEICAYAAACZA4KlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAQH0lEQVR4nO3de5CV9X3H8c9HxRAvUeiuBBHBKmlqmQTtVnS0SrTxQsdBMxMTJxpojViD1TQmjWObajtpxjiNlzTGDBEjqPWSKANNqVFJ1MTWy6rIJU68zSIwC+yGqFilAn77x3lIF9zz291zZ3/v18yZPef5nud5vnvgs885z+X8HBECMPzt0ewGADQGYQcyQdiBTBB2IBOEHcgEYQcyQdgzZvsR219o9LxoDsI+DNjusv1nze5jMGwvtR2292p2L7kh7GgY25+TNKLZfeSKsA9jtkfZ/ontHtu/Le4fssvTDrf9lO03bS+yPbrP/Mfa/i/br9t+3va0Kno5QNJVkv620mWgOoR9eNtD0g8lTZB0qKR3JH13l+d8XtJfShoraZuk70iS7XGS/kPSNySNlvQVSffZbt91JbYPLf4gHJro5ZuSbpa0vppfCJUj7MNYRPwmIu6LiLcjYrOkf5Z00i5Puz0iVkbE/0j6uqRzbO8p6TxJSyJiSUS8FxEPSeqUNL2f9bwWEQdGxGv99WG7Q9Lxkv61hr8ehoidJMOY7X0kXS/pdEmjisn7294zIrYXj9f0mWW1Sp+p21R6N/Bp22f2qY+Q9PMh9rCHpO9Juiwittke+i+CmiDsw9vlkv5A0tSIWG97iqTnJPVN3Pg+9w+VtFVSr0p/BG6PiAur7OFDkjok3VMEfc9i+lrbn46IX1S5fAwSYR8+Rtge2efxNkn7q/Q5/fVix9tV/cx3nu0Fkrok/ZOkH0fEdtt3SHra9mmSHlZpq36spJcjYu0Q+npD0sF9Ho+X9JSkP5bUM4TloEp8Zh8+lqgU7B23qyXdIOmDKm2pn5D0QD/z3S7pNpV2nI2UdKkkRcQaSTMkXalSKNdI+qr6+T9T7KB7q78ddFGyfsdN/x/wDRHxbqW/LIbOfHkFkAe27EAmCDuQCcIOZIKwA5lo6KG3tra2mDBhYiNXCWRl9eou9fb29nvmUlVht326pBtVOlHiloi4JvX8CRMm6vEnO6tZJYCE46d2lK1V/Da+OH/6JklnSDpS0rm2j6x0eQDqq5rP7MeodDbVq8XJEXerdBIGgBZUTdjHaeeLKNYW03Zie7btTtudPb2cHQk0S933xkfE3IjoiIiO9rb3XQoNoEGqCfs67XzF1CHFNAAtqJqwPy1pku3DbO8t6bOSFtemLQC1VvGht+KLCC6R9FOVDr3dGhGratYZgJqq6jh7RCxR6dJKAC2O02WBTBB2IBOEHcgEYQcyQdiBTBB2IBOEHcgEYQcyQdiBTBB2IBOEHcgEYQcyQdiBTBB2IBOEHcgEYQcyQdiBTBB2IBOEHcgEYQcyQdiBTDR0yGZgdzH5iv9M1iMiWV/1rem1bKcm2LIDmSDsQCYIO5AJwg5kgrADmSDsQCYIO5AJjrMjS7PufC5ZX/f4o8n6yTM/Vct2GqKqsNvukrRZ0nZJ2yKioxZNAai9WmzZPxERvTVYDoA64jM7kIlqwx6SHrT9jO3Z/T3B9mzbnbY7e3p7qlwdgEpVG/YTIuJoSWdImmP7xF2fEBFzI6IjIjra29qrXB2ASlUV9ohYV/zcKGmhpGNq0RSA2qs47Lb3tb3/jvuSTpW0slaNAaitavbGj5G00PaO5fxbRDxQk66AGrj4R8vL1hZ9/570zCM+kCzPOvaQSlpqqorDHhGvSvp4DXsBUEccegMyQdiBTBB2IBOEHcgEYQcywSWuGLYeeWpN+eLWLcl5x//ptGT9zMkHV9BRc7FlBzJB2IFMEHYgE4QdyARhBzJB2IFMEHYgExxnH+aWdb2erM+65clk/dErT07WD9hnxJB7qpWFy9cm6+tXlP96hb2OOCo5732XnlBRT62MLTuQCcIOZIKwA5kg7EAmCDuQCcIOZIKwA5ngOPswd+rXFyfrW198JlnvunBqsv7xCQcOuada+eL16WGV9Zvy17Pfcd3M5KyTPrxfJS21NLbsQCYIO5AJwg5kgrADmSDsQCYIO5AJwg5kguPsw9zIfUYm61tLQ26XtWXbe7VsZ0he7N6crG9Z/WJ6AXvsWbb09rZtlbS0Wxtwy277Vtsbba/sM2207Ydsv1T8HFXfNgFUazBv42+TdPou066QtDQiJklaWjwG0MIGDHtEPCZp0y6TZ0iaX9yfL+msGvcFoMYq3UE3JiK6i/vrJY0p90Tbs2132u7s6e2pcHUAqlX13viICEmRqM+NiI6I6Ghva692dQAqVGnYN9geK0nFz421awlAPVQa9sWSdlwjOFPSotq0A6BeBjzObvsuSdMktdleK+kqSddIutf2BZJWSzqnnk0i7bKFq8rWNi9/IjnvyD/8k2T9I3W8rvudd7cn6xff/Vx6AW+/kSy3HVf+O+/P/KPdb3z1ag0Y9og4t0zplBr3AqCOOF0WyARhBzJB2IFMEHYgE4QdyASXuO4GNryxJVlfMO/B8sW99k7Ou+SqP0/WR+2bnr8a5y1If431s/fcn17AuI8myy/dMGOoLQ1rbNmBTBB2IBOEHcgEYQcyQdiBTBB2IBOEHcgEx9lbwCsb3krWp/7Nj9ML6F1dtjTjr9NDEx81sb5DLn9zafmve/7ZD39U1bKv/eppVc2fG7bsQCYIO5AJwg5kgrADmSDsQCYIO5AJwg5kguPsNbBte3pY43ufX5Osz7n4uvQK3kt/5XJqaOJfPNGVnPXvR38wWf+HT34kWX/zna3J+i0LV5YvRvp1O37WZ5L1C489LFnHztiyA5kg7EAmCDuQCcIOZIKwA5kg7EAmCDuQCY6z18DCFeuS9TlfvD69ADtdTxxHl6S9Jh1dtrbp6UeT8940QP2uJScl65vWrk/W1f3r8rX2iclZf/JXx6WXjSEZcMtu+1bbG22v7DPtatvrbC8rbtPr2yaAag3mbfxtkk7vZ/r1ETGluC2pbVsAam3AsEfEY5I2NaAXAHVUzQ66S2wvL97mjyr3JNuzbXfa7uzp7alidQCqUWnYb5Z0uKQpkrolfbvcEyNibkR0RERHe1t7hasDUK2Kwh4RGyJie0S8J+kHko6pbVsAaq2isNse2+fh2ZIS1zECaAUDHme3fZekaZLabK+VdJWkabanSApJXZIuqmOPLWFR4lj67IsHOI4+YmS6fuCHk+WHv5P+7vf9R5b/Z/zUjQcl5133yE+T9YGO0ysiXU+dQ9D7WnLWUWffnKyvmDcrWT9kgGv1czNg2CPi3H4mz6tDLwDqiNNlgUwQdiAThB3IBGEHMkHYgUxwiesgXXnH82VrnjA5Oe+NXzklWT+/Y0JFPQ3Gv3/5xGT9tP9NfxV0z3//rJbt7GyAr5KeesrHknUOrQ0NW3YgE4QdyARhBzJB2IFMEHYgE4QdyARhBzLBcfZBumB6+aGLPzfl5OS8Yw4Y4BLXOnrj7QGOo69cXtXyF8z7WrI++aADKl72QR/6QMXz4v3YsgOZIOxAJgg7kAnCDmSCsAOZIOxAJgg7kAmOsw/Sl086otktlPXWlm1la9965OX0zG+mh+Ta64jyw0FL0pmTD04vHy2DLTuQCcIOZIKwA5kg7EAmCDuQCcIOZIKwA5kYzJDN4yUtkDRGpSGa50bEjbZHS7pH0kSVhm0+JyJ+W79WUc61j7xStvbA9+9Iz3zQYcnyqu99ppKW0IIGs2XfJunyiDhS0rGS5tg+UtIVkpZGxCRJS4vHAFrUgGGPiO6IeLa4v1nSC5LGSZohaX7xtPmSzqpXkwCqN6TP7LYnSjpK0pOSxkREd1Far9LbfAAtatBht72fpPskfSki3uxbi4hQ6fN8f/PNtt1pu7OnN30eNoD6GVTYbY9QKeh3RsT9xeQNtscW9bGSNvY3b0TMjYiOiOhob2uvRc8AKjBg2G1b0jxJL0TEdX1KiyXNLO7PlLSo9u0BqJXBXOJ6vKTzJa2wvayYdqWkayTda/sCSaslnVOfFtH9+pZk/bu3PV6+6PTf87/4wqnJ+kFN/Bps1NaAYY+IX0pymXJ64HEALYMz6IBMEHYgE4QdyARhBzJB2IFMEHYgE3yV9G7gY3PuSdajq/ywy8d9Pn36w3UzjqyoJ+x+2LIDmSDsQCYIO5AJwg5kgrADmSDsQCYIO5AJjrPvBi46b2qyftM/Ple2dum09FdFIx9s2YFMEHYgE4QdyARhBzJB2IFMEHYgE4QdyATH2XcD3zjjowPUb2hQJ9idsWUHMkHYgUwQdiAThB3IBGEHMkHYgUwQdiATA4bd9njbP7f9K9urbF9WTL/a9jrby4rb9Pq3C6BSgzmpZpukyyPiWdv7S3rG9kNF7fqI+Jf6tQegVgYMe0R0S+ou7m+2/YKkcfVuDEBtDekzu+2Jko6S9GQx6RLby23fantUmXlm2+603dnT21NVswAqN+iw295P0n2SvhQRb0q6WdLhkqaotOX/dn/zRcTciOiIiI72tvYatAygEoMKu+0RKgX9zoi4X5IiYkNEbI+I9yT9QNIx9WsTQLUGszfekuZJeiEiruszfWyfp50taWXt2wNQK4PZG3+8pPMlrbC9rJh2paRzbU+RFJK6JF1Ulw4B1MRg9sb/UpL7KS2pfTsA6oUz6IBMEHYgE4QdyARhBzJB2IFMEHYgE4QdyARhBzJB2IFMEHYgE4QdyARhBzJB2IFMEHYgE46Ixq3M7pG0us+kNkm9DWtgaFq1t1btS6K3StWytwkR0e/3vzU07O9bud0ZER1NayChVXtr1b4keqtUo3rjbTyQCcIOZKLZYZ/b5PWntGpvrdqXRG+VakhvTf3MDqBxmr1lB9AghB3IRFPCbvt027+2/bLtK5rRQzm2u2yvKIah7mxyL7fa3mh7ZZ9po20/ZPul4me/Y+w1qbeWGMY7Mcx4U1+7Zg9/3vDP7Lb3lPSipE9KWivpaUnnRsSvGtpIGba7JHVERNNPwLB9oqS3JC2IiMnFtGslbYqIa4o/lKMi4mst0tvVkt5q9jDexWhFY/sOMy7pLEmz1MTXLtHXOWrA69aMLfsxkl6OiFcj4l1Jd0ua0YQ+Wl5EPCZp0y6TZ0iaX9yfr9J/loYr01tLiIjuiHi2uL9Z0o5hxpv62iX6aohmhH2cpDV9Hq9Va433HpIetP2M7dnNbqYfYyKiu7i/XtKYZjbTjwGH8W6kXYYZb5nXrpLhz6vFDrr3OyEijpZ0hqQ5xdvVlhSlz2CtdOx0UMN4N0o/w4z/TjNfu0qHP69WM8K+TtL4Po8PKaa1hIhYV/zcKGmhWm8o6g07RtAtfm5scj+/00rDePc3zLha4LVr5vDnzQj705Im2T7M9t6SPitpcRP6eB/b+xY7TmR7X0mnqvWGol4saWZxf6akRU3sZSetMox3uWHG1eTXrunDn0dEw2+Spqu0R/4VSX/XjB7K9PX7kp4vbqua3Zuku1R6W7dVpX0bF0j6PUlLJb0k6WFJo1uot9slrZC0XKVgjW1Sbyeo9BZ9uaRlxW16s1+7RF8Ned04XRbIBDvogEwQdiAThB3IBGEHMkHYgUwQdiAThB3IxP8BpNDMEuTHhMUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FX2fW3PLdrvI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f6d14462-a490-45b1-d6bc-02f851ec65ca"
      },
      "source": [
        "mnist_dataset[9]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4,\n",
              " tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7412,\n",
              "         0.7451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5608,\n",
              "         0.9686, 0.6000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5333,\n",
              "         0.9686, 0.9490, 0.3373, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.7529, 0.9882, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.2431, 0.7255, 0.0706, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.3490, 0.9255, 0.8510, 0.1843, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.8471, 0.9922, 0.2353, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.8314, 1.0000, 0.3176, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.8078, 0.9882, 0.2667, 0.0000, 0.0000,\n",
              "         0.0000, 0.1882, 0.9490, 0.9922, 0.3490, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.5137, 0.9843, 0.8314, 0.0824, 0.0000,\n",
              "         0.0000, 0.0431, 0.6549, 0.9882, 0.7725, 0.0196, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.1137, 0.9098, 0.9686, 0.2471, 0.0000,\n",
              "         0.0000, 0.0000, 0.6000, 0.9882, 0.8863, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.8588, 0.9882, 0.5608, 0.0000,\n",
              "         0.0000, 0.0000, 0.4549, 0.9765, 0.9882, 0.4039, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0157, 0.3765, 0.9922, 1.0000, 0.9922, 0.7843,\n",
              "         0.4784, 0.0275, 0.0980, 0.7882, 0.9804, 0.6196, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.3608, 0.9882, 0.9882, 0.9922, 0.8510,\n",
              "         0.9882, 0.9882, 0.7843, 0.8902, 0.9882, 0.9059, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.3412, 0.9843, 0.9686, 0.9059, 0.2549,\n",
              "         0.1882, 0.7412, 0.9882, 0.9882, 0.9922, 0.9882, 0.9843, 0.8902, 0.1373,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7451, 0.8667, 0.3843, 0.0000,\n",
              "         0.0000, 0.0000, 0.1647, 0.7686, 0.9882, 0.9922, 0.9882, 0.9882, 0.6353,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4353, 0.1137, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.2431, 0.9373, 0.9882, 0.3373, 0.1647, 0.1647,\n",
              "         0.0549, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0588, 0.5804, 0.9922, 0.8549, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.4745, 0.9882, 0.9059, 0.1098, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.1216, 0.8667, 0.9843, 0.5059, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8549, 0.9882, 0.6275, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4784, 0.9882, 0.3216,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000]),\n",
              " tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdAuovtrfWWb",
        "colab_type": "text"
      },
      "source": [
        "Neural network class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTr1Mz6kAqGp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# neural network class\n",
        "class Classifier(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    # initialise parent pytorch class\n",
        "    super().__init__()\n",
        "\n",
        "    # setup neural network architecture\n",
        "    self.model = nn.Sequential(\n",
        "        nn.Linear( 784, 200), #  fully connected mapping from 784 nodes to 200 nodes\n",
        "        nn.Sigmoid(),  # apply sigmoid to ouput of 200 nodes\n",
        "        nn.Linear(200, 10),  # maps 200 nodes to 10 nodes\n",
        "        nn.Sigmoid()  # apply sigmoid to output of 10 nodes to get final output\n",
        "    )\n",
        "\n",
        "    # setup loss function\n",
        "    self.loss_function = torch.nn.MSELoss()\n",
        "\n",
        "    # setup optimiser using simple stochastic gradient descent\n",
        "    self.optimiser = torch.optim.SGD(self.parameters(), lr=0.01)\n",
        "\n",
        "    # counter and accumulator to track progress\n",
        "    self.counter = 0\n",
        "    self.progress = []\n",
        "\n",
        "    # setup forward method for passing information through network\n",
        "    def forward(self, inputs):\n",
        "      # run the model\n",
        "      return self.model(inputs)\n",
        "\n",
        "    def train(self, inputs, targets):\n",
        "      # calculate nn outputs\n",
        "      outputs = self.forward(inputs)\n",
        "\n",
        "      # calculate loss\n",
        "      loss = self.loss_function(outputs, targets)\n",
        "\n",
        "      # update training progress trackers, accumulate loss val after 10 train ex\n",
        "      self.counter += 1\n",
        "      if (self.counter % 10):  \n",
        "        self.progress.append(loss.item())  # loss.item() unwraps tensor\n",
        "        \n",
        "      # indicate speed of training to user\n",
        "      if (self.counter % 10000 == 0):\n",
        "        print(\"counter = \", self.counter)\n",
        "\n",
        "      # process nn updates\n",
        "      self.optimiser().zero_grad() # set gradients to zero\n",
        "      loss.backward() # calculate gradients via backward pass\n",
        "      self.optimiser.step() # update nn weights using gradients\n",
        "\n",
        "    def plot_progress(self):\n",
        "      df = pandas.Dataframe(self.progress, columns[[\"loss\"]])\n",
        "      df.plot(ylim=(0, 1.0), figsize=(16, 8), alpha=0.1, marker=\".\",\n",
        "              grid=True, yticks=(0, 0.25, 0.5))\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}